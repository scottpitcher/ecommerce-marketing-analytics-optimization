{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep and Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "print(\"Packages successfully imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/data_raw.csv\")\n",
    "\n",
    "print(\"Data successfully imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The dataset has {data.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupl = data['Customer ID'].value_counts()[data['Customer ID'].value_counts()>1].size\n",
    "print(f\"Duplicates: {dupl}\")\n",
    "# No customer duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove the two rows with NA's as there's only two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = data.dropna()\n",
    "\n",
    "print(f\"The new dataset has {data_full.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting counts and summary stats for cat and numeric vars, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting numeric columns\n",
    "numeric_stats = data_full.describe()\n",
    "\n",
    "# For categorical columns\n",
    "categorical_columns = data_full.select_dtypes(include=['object', 'category']).columns\n",
    "categorical_values = {col: data_full[col].value_counts() for col in categorical_columns}\n",
    "\n",
    "# Display results\n",
    "print(\"Numeric Stats:\\n\", numeric_stats)\n",
    "print(\"\\nCategorical Values:\")\n",
    "for col, values in categorical_values.items():\n",
    "    print(f\"\\n{col}:\\n\", values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting pie charts for the categorical vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2 grid for the pie charts\n",
    "fig, axes = plt.subplots(2, 2, figsize=(9, 8))\n",
    "\n",
    "# Flatten the axes array for iter\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(categorical_columns):\n",
    "    # get value counts for the column\n",
    "    values = data_full[col].value_counts()\n",
    "    \n",
    "    # plot pie chart on the corresponding axis\n",
    "    axes[i].pie(values, labels=values.index, autopct='%1.1f%%', startangle=140, \n",
    "                colors=palette[:len(values)])\n",
    "    \n",
    "    # setting the title for each subplot\n",
    "    axes[i].set_title(f'Distribution of {col}', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # equal aspect ratio ensures circle\n",
    "    axes[i].axis('equal')\n",
    "\n",
    "# Adjust layout, prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables seem to have very equal distributions, we will now inspect the numeric vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = data_full.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Create a 2x2 grid for the pie charts\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 10))\n",
    "\n",
    "# Flatten the axes array for iter\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    # Plot box plot on the corresponding axis\n",
    "    sns.boxplot(y=data_full[col], ax=axes[i], color=sns.color_palette(\"Set2\")[i])\n",
    "    \n",
    "    # Set the title for each subplot\n",
    "    axes[i].set_title(f'Box Plot of {col}', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Adjust layout, prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [col for col in numeric_columns if col != \"Customer ID\"]\n",
    "\n",
    "# Create a 2x2 grid for the histogram\n",
    "fig, axes = plt.subplots(2, 3, figsize=(9, 8))\n",
    "\n",
    "# Flatten the axes array for iter\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    # Plot histogram on the corresponding axis\n",
    "    axes[i].hist(data_full[col], bins=20, color=sns.color_palette(\"Set2\")[i], edgecolor='black')\n",
    "    \n",
    "    # Set the title for each subplot\n",
    "    axes[i].set_title(f'Distribution of {col}', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Set labels\n",
    "    axes[i].set_xlabel(col, fontsize=12)\n",
    "    axes[i].set_ylabel('Frequency', fontsize=12)\n",
    "\n",
    "# Adjust layout, prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the data is cleaned (in the proper structure), we will need to one-hot encode the cat vars for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data_encoded = data_full.copy()\n",
    "# Create a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Initialize a dictionary to store the encoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Apply label encoding to each categorical column\n",
    "for col in data_encoded.select_dtypes(include=['object', 'category']).columns:\n",
    "    data_encoded[col] = label_encoder.fit_transform(data_encoded[col])\n",
    "    \n",
    "    # Save the encoder mapping\n",
    "    label_encoders[col] = {class_label: int(value) for class_label, value in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))}\n",
    "\n",
    "    print(f\"Encoded {col}: {label_encoders[col]}\")\n",
    "\n",
    "# reverse_mapping = {v: k for k, v in label_encoders[''].items()}\n",
    "data_encoded.head()\n",
    "\n",
    "# saving the encoded data\n",
    "data_encoded.to_csv('data/data_encoded.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will normalise the numerical values in order to ensure equal contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "data_normal = data_encoded.copy()\n",
    "colnames = data_encoded.columns\n",
    "\n",
    "data_normal[numeric_columns] = scaler.fit_transform(data_normal[numeric_columns])\n",
    "\n",
    "data_normal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing distributions of normalised numeric vars, they should be identical\n",
    "for col in numeric_columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(9, 8))\n",
    "    sns.histplot(data_encoded[col], ax = axes[0], color=sns.color_palette(\"Set2\")[0])\n",
    "    axes[0].set_title(f'Histogram of {col} before normalization', fontsize=8, fontweight='bold')\n",
    "    sns.histplot(data_normal[col], ax= axes[1], color=sns.color_palette(\"Set2\")[1])\n",
    "    axes[1].set_title(f'Histogram of {col} After normalization', fontsize=8, fontweight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving normalised data\n",
    "data_normal.to_csv('data/data_normal.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pairplot to compare variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_encoded)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit crowded, let's try something else!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll compare the correlations of each variable with each other! Using this, we can discern which variables we want to take a closer look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = data_normal.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n",
    "\n",
    "plt.title(\"Correlation Heatmap\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, obviously customer ID isn't related to any variable, and items purchased is highly correlated with items bought. One notable insight from this plot is Total Spend being so highly correlated with City, we'll investigate this further!\n",
    "\n",
    "Overall, we're gonna take the relationships with a correlation of r ≥ ±0.7 to investigate further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr_matrix = data_encoded.corr().abs()\n",
    "\n",
    "# Set the lower triangle and the diagonal of the matrix to 0 to avoid double-counting and self-correlation\n",
    "corr_matrix.values[np.tril_indices_from(corr_matrix)] = 0\n",
    "\n",
    "# Find all pairs where correlation is greater than or equal to 0.7\n",
    "high_corr_pairs = corr_matrix[corr_matrix >= 0.7].stack().sort_values(ascending=False)\n",
    "\n",
    "# Display the pairs\n",
    "print(\"Highly correlated pairs with r >= ±0.7:\\n\")\n",
    "for index, value in high_corr_pairs.items():\n",
    "    print(f\"{index[0]:<25}~ {index[1]:<30}--> r = {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, value in high_corr_pairs.items():\n",
    "    var1 = index[0]\n",
    "    var2 = index[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
