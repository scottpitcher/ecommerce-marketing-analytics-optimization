{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Life Value Optimization Model\n",
    "Goal: Develop a model using A/B testing to strategise discount targeting for maximised Customer Life Value (CLV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Membership Type</th>\n",
       "      <th>Total Spend</th>\n",
       "      <th>Items Purchased</th>\n",
       "      <th>Average Rating</th>\n",
       "      <th>Discount Applied</th>\n",
       "      <th>Days Since Last Purchase</th>\n",
       "      <th>Satisfaction Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1120.20</td>\n",
       "      <td>14</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>780.50</td>\n",
       "      <td>11</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>510.75</td>\n",
       "      <td>9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1480.30</td>\n",
       "      <td>19</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>720.40</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  City  Membership Type  Total Spend  Items Purchased  \\\n",
       "0       0   29     4                1      1120.20               14   \n",
       "1       1   34     2                2       780.50               11   \n",
       "2       0   43     0                0       510.75                9   \n",
       "3       1   30     5                1      1480.30               19   \n",
       "4       1   27     3                2       720.40               13   \n",
       "\n",
       "   Average Rating  Discount Applied  Days Since Last Purchase  \\\n",
       "0             4.6                 1                        25   \n",
       "1             4.1                 0                        18   \n",
       "2             3.4                 1                        42   \n",
       "3             4.7                 0                        12   \n",
       "4             4.0                 1                        55   \n",
       "\n",
       "   Satisfaction Level  \n",
       "0                   1  \n",
       "1                   0  \n",
       "2                   2  \n",
       "3                   1  \n",
       "4                   2  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing index, and customer ID columns\n",
    "# We use the encoded data, not normalized; we only want the features normal, not the output\n",
    "data = pd.read_csv(\"data/data_encoded.csv\").drop(columns=[\"Unnamed: 0\", \"Customer ID\"])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 348 entries, 0 to 347\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Gender                    348 non-null    int64  \n",
      " 1   Age                       348 non-null    int64  \n",
      " 2   City                      348 non-null    int64  \n",
      " 3   Membership Type           348 non-null    int64  \n",
      " 4   Total Spend               348 non-null    float64\n",
      " 5   Items Purchased           348 non-null    int64  \n",
      " 6   Average Rating            348 non-null    float64\n",
      " 7   Discount Applied          348 non-null    int64  \n",
      " 8   Days Since Last Purchase  348 non-null    int64  \n",
      " 9   Satisfaction Level        348 non-null    int64  \n",
      "dtypes: float64(2), int64(8)\n",
      "memory usage: 27.3 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Interaction Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing, there are vital insights from the ETL script that we must acknowledge prior to modelling:\n",
    "- Customers' Genders are (mostly) segregated by City\n",
    "- Whether or not a customer receieved a Discount is entirely based on City\n",
    "\n",
    "Because of this, *City* must be treated as a *confounding variable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City_Houston</th>\n",
       "      <th>City_Los Angeles</th>\n",
       "      <th>City_Miami</th>\n",
       "      <th>City_New York</th>\n",
       "      <th>City_San Francisco</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Discount Applied_True</th>\n",
       "      <th>Membership Type_Gold</th>\n",
       "      <th>Membership Type_Silver</th>\n",
       "      <th>Satisfaction Level_Satisfied</th>\n",
       "      <th>Satisfaction Level_Unsatisfied</th>\n",
       "      <th>Satisfaction Level_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   City_Houston  City_Los Angeles  City_Miami  City_New York  \\\n",
       "0           0.0               0.0         0.0            1.0   \n",
       "1           0.0               1.0         0.0            0.0   \n",
       "2           0.0               0.0         0.0            0.0   \n",
       "3           0.0               0.0         0.0            0.0   \n",
       "4           0.0               0.0         1.0            0.0   \n",
       "\n",
       "   City_San Francisco  Gender_Male  Discount Applied_True  \\\n",
       "0                 0.0          0.0                    1.0   \n",
       "1                 0.0          1.0                    0.0   \n",
       "2                 0.0          0.0                    1.0   \n",
       "3                 1.0          1.0                    0.0   \n",
       "4                 0.0          1.0                    1.0   \n",
       "\n",
       "   Membership Type_Gold  Membership Type_Silver  Satisfaction Level_Satisfied  \\\n",
       "0                   1.0                     0.0                           1.0   \n",
       "1                   0.0                     1.0                           0.0   \n",
       "2                   0.0                     0.0                           0.0   \n",
       "3                   1.0                     0.0                           1.0   \n",
       "4                   0.0                     1.0                           0.0   \n",
       "\n",
       "   Satisfaction Level_Unsatisfied  Satisfaction Level_nan  \n",
       "0                             0.0                     0.0  \n",
       "1                             0.0                     0.0  \n",
       "2                             1.0                     0.0  \n",
       "3                             0.0                     0.0  \n",
       "4                             1.0                     0.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/data_raw.csv\").drop(columns=[ \"Customer ID\"])\n",
    "# Creating interaction terms between interaction features\n",
    "cat_vars = ['City', 'Gender', 'Discount Applied', 'Membership Type', 'Satisfaction Level']\n",
    "\n",
    "# Apply OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_cats = encoder.fit_transform(data[cat_vars])\n",
    "encoded_cat_names = encoder.get_feature_names_out(cat_vars)\n",
    "encoded_df = pd.DataFrame(encoded_cats, columns=encoded_cat_names) # Dropping a col that has 0 vals\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Total Spend</th>\n",
       "      <th>Items Purchased</th>\n",
       "      <th>Average Rating</th>\n",
       "      <th>Days Since Last Purchase</th>\n",
       "      <th>City_Houston</th>\n",
       "      <th>City_Los Angeles</th>\n",
       "      <th>City_Miami</th>\n",
       "      <th>City_New York</th>\n",
       "      <th>City_San Francisco</th>\n",
       "      <th>...</th>\n",
       "      <th>Satisfaction Level_Satisfied Satisfaction Level_Unsatisfied</th>\n",
       "      <th>Satisfaction Level_Satisfied Satisfaction Level_nan</th>\n",
       "      <th>Satisfaction Level_Satisfied Average Rating</th>\n",
       "      <th>Satisfaction Level_Satisfied Age</th>\n",
       "      <th>Satisfaction Level_Unsatisfied Satisfaction Level_nan</th>\n",
       "      <th>Satisfaction Level_Unsatisfied Average Rating</th>\n",
       "      <th>Satisfaction Level_Unsatisfied Age</th>\n",
       "      <th>Satisfaction Level_nan Average Rating</th>\n",
       "      <th>Satisfaction Level_nan Age</th>\n",
       "      <th>Average Rating Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>1120.20</td>\n",
       "      <td>14</td>\n",
       "      <td>4.6</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>780.50</td>\n",
       "      <td>11</td>\n",
       "      <td>4.1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>510.75</td>\n",
       "      <td>9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>1480.30</td>\n",
       "      <td>19</td>\n",
       "      <td>4.7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>720.40</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Total Spend  Items Purchased  Average Rating  \\\n",
       "0   29      1120.20               14             4.6   \n",
       "1   34       780.50               11             4.1   \n",
       "2   43       510.75                9             3.4   \n",
       "3   30      1480.30               19             4.7   \n",
       "4   27       720.40               13             4.0   \n",
       "\n",
       "   Days Since Last Purchase  City_Houston  City_Los Angeles  City_Miami  \\\n",
       "0                        25           0.0               0.0         0.0   \n",
       "1                        18           0.0               1.0         0.0   \n",
       "2                        42           0.0               0.0         0.0   \n",
       "3                        12           0.0               0.0         0.0   \n",
       "4                        55           0.0               0.0         1.0   \n",
       "\n",
       "   City_New York  City_San Francisco  ...  \\\n",
       "0            1.0                 0.0  ...   \n",
       "1            0.0                 0.0  ...   \n",
       "2            0.0                 0.0  ...   \n",
       "3            0.0                 1.0  ...   \n",
       "4            0.0                 0.0  ...   \n",
       "\n",
       "   Satisfaction Level_Satisfied Satisfaction Level_Unsatisfied  \\\n",
       "0                                                0.0             \n",
       "1                                                0.0             \n",
       "2                                                0.0             \n",
       "3                                                0.0             \n",
       "4                                                0.0             \n",
       "\n",
       "   Satisfaction Level_Satisfied Satisfaction Level_nan  \\\n",
       "0                                                0.0     \n",
       "1                                                0.0     \n",
       "2                                                0.0     \n",
       "3                                                0.0     \n",
       "4                                                0.0     \n",
       "\n",
       "   Satisfaction Level_Satisfied Average Rating  \\\n",
       "0                                          4.6   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          4.7   \n",
       "4                                          0.0   \n",
       "\n",
       "   Satisfaction Level_Satisfied Age  \\\n",
       "0                              29.0   \n",
       "1                               0.0   \n",
       "2                               0.0   \n",
       "3                              30.0   \n",
       "4                               0.0   \n",
       "\n",
       "   Satisfaction Level_Unsatisfied Satisfaction Level_nan  \\\n",
       "0                                                0.0       \n",
       "1                                                0.0       \n",
       "2                                                0.0       \n",
       "3                                                0.0       \n",
       "4                                                0.0       \n",
       "\n",
       "   Satisfaction Level_Unsatisfied Average Rating  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            3.4   \n",
       "3                                            0.0   \n",
       "4                                            4.0   \n",
       "\n",
       "   Satisfaction Level_Unsatisfied Age  Satisfaction Level_nan Average Rating  \\\n",
       "0                                 0.0                                    0.0   \n",
       "1                                 0.0                                    0.0   \n",
       "2                                43.0                                    0.0   \n",
       "3                                 0.0                                    0.0   \n",
       "4                                27.0                                    0.0   \n",
       "\n",
       "   Satisfaction Level_nan Age  Average Rating Age  \n",
       "0                         0.0               133.4  \n",
       "1                         0.0               139.4  \n",
       "2                         0.0               146.2  \n",
       "3                         0.0               141.0  \n",
       "4                         0.0               108.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_enc = pd.concat([data, encoded_df], axis=1).drop(columns=cat_vars) # Dropping the non-encoded columns\n",
    "\n",
    "interaction_features = encoded_cat_names.tolist() + ['Average Rating', 'Age']\n",
    "poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "interaction_terms = poly.fit_transform(data_enc[interaction_features])\n",
    "\n",
    "# Convert interaction terms to DataFrame and add to the main data\n",
    "interaction_term_names = poly.get_feature_names_out(interaction_features)\n",
    "interaction_df = pd.DataFrame(interaction_terms, columns=interaction_term_names)\n",
    "\n",
    "data1 = pd.concat([data_enc, interaction_df], axis=1)\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age</th>\n",
       "      <th>Items Purchased</th>\n",
       "      <th>Days Since Last Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.945152</td>\n",
       "      <td>-0.945152</td>\n",
       "      <td>0.337346</td>\n",
       "      <td>-0.118359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082826</td>\n",
       "      <td>0.082826</td>\n",
       "      <td>-0.385538</td>\n",
       "      <td>-0.639907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.933185</td>\n",
       "      <td>1.933185</td>\n",
       "      <td>-0.867461</td>\n",
       "      <td>1.148256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.739557</td>\n",
       "      <td>-0.739557</td>\n",
       "      <td>1.542153</td>\n",
       "      <td>-1.086947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.356343</td>\n",
       "      <td>-1.356343</td>\n",
       "      <td>0.096385</td>\n",
       "      <td>2.116844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age       Age  Items Purchased  Days Since Last Purchase\n",
       "0 -0.945152 -0.945152         0.337346                 -0.118359\n",
       "1  0.082826  0.082826        -0.385538                 -0.639907\n",
       "2  1.933185  1.933185        -0.867461                  1.148256\n",
       "3 -0.739557 -0.739557         1.542153                 -1.086947\n",
       "4 -1.356343 -1.356343         0.096385                  2.116844"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "data_scaled = data1.copy()\n",
    "numerical_features = [\"Age\", \"Items Purchased\", \"Days Since Last Purchase\"]\n",
    "data_scaled[numerical_features] = scaler.fit_transform(data_scaled[numerical_features])\n",
    "data_scaled[numerical_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X, y Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_scaled.drop(columns=['Total Spend'])  # Assuming 'Total Spend' is the target variable\n",
    "y = data_scaled['Total Spend']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['Age', 'Items Purchased', 'Average Rating', 'Days Since Last Purchase',\n",
      "       'City_Houston', 'City_Miami', 'City_New York', 'City_San Francisco',\n",
      "       'Gender_Male', 'Membership Type_Gold', 'Satisfaction Level_Unsatisfied',\n",
      "       'City_Miami', 'Gender_Male', 'Average Rating', 'Age',\n",
      "       'City_Houston Average Rating', 'City_Houston Age',\n",
      "       'City_Los Angeles Satisfaction Level_Satisfied',\n",
      "       'City_Los Angeles Average Rating', 'City_Los Angeles Age',\n",
      "       'City_Miami Gender_Male', 'City_Miami Average Rating', 'City_Miami Age',\n",
      "       'City_New York Discount Applied_True',\n",
      "       'City_New York Membership Type_Gold', 'City_New York Average Rating',\n",
      "       'City_New York Age', 'City_San Francisco Gender_Male',\n",
      "       'City_San Francisco Membership Type_Gold',\n",
      "       'City_San Francisco Satisfaction Level_Satisfied',\n",
      "       'City_San Francisco Average Rating', 'City_San Francisco Age',\n",
      "       'Gender_Male Discount Applied_True',\n",
      "       'Gender_Male Membership Type_Silver',\n",
      "       'Gender_Male Satisfaction Level_Satisfied',\n",
      "       'Gender_Male Average Rating', 'Gender_Male Age',\n",
      "       'Discount Applied_True Satisfaction Level_Unsatisfied',\n",
      "       'Discount Applied_True Average Rating', 'Discount Applied_True Age',\n",
      "       'Membership Type_Gold Average Rating', 'Membership Type_Gold Age',\n",
      "       'Membership Type_Silver Satisfaction Level_Unsatisfied',\n",
      "       'Membership Type_Silver Average Rating', 'Membership Type_Silver Age',\n",
      "       'Satisfaction Level_Satisfied Average Rating',\n",
      "       'Satisfaction Level_Satisfied Age',\n",
      "       'Satisfaction Level_Unsatisfied Average Rating',\n",
      "       'Satisfaction Level_Unsatisfied Age', 'Satisfaction Level_nan Age',\n",
      "       'Average Rating Age'],\n",
      "      dtype='object')\n",
      "Lasso Coefficients: [-1.39886960e+02  1.22742208e+02  1.79184401e+01 -1.31889971e+01\n",
      " -5.95555480e+00  0.00000000e+00 -1.01880407e+02  3.52869754e+01\n",
      "  1.72858551e+02 -1.23331012e+01 -0.00000000e+00  6.64440136e+01\n",
      " -0.00000000e+00  0.00000000e+00 -1.65566135e+01 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -1.23380297e+00  0.00000000e+00\n",
      "  0.00000000e+00 -1.74081567e-01 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -7.94247065e+01  7.00326139e+01  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  1.24198204e+00 -3.14362168e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.04900256e+01  0.00000000e+00\n",
      "  0.00000000e+00 -2.56801583e+01  1.24190877e+00  0.00000000e+00\n",
      "  0.00000000e+00 -1.24839947e+01 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  1.07966228e+01  2.06318973e+00  0.00000000e+00 -0.00000000e+00\n",
      "  4.91005804e+01  2.89696497e-15  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  4.86920047e+00  4.26603314e+00\n",
      "  1.21970729e+02  0.00000000e+00  9.10414346e-15  0.00000000e+00\n",
      "  1.17472819e-15  0.00000000e+00  0.00000000e+00  1.72511167e+01\n",
      " -4.54191035e-01 -3.36292539e+00 -0.00000000e+00  2.87947877e+01\n",
      " -1.87486132e+01 -0.00000000e+00  0.00000000e+00 -1.87291201e+00\n",
      "  1.15654680e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -7.69287955e+01  0.00000000e+00 -2.48209826e+01  2.91826697e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -5.82199469e+00  1.84029454e+00 -0.00000000e+00  2.09191030e+01\n",
      "  0.00000000e+00  4.76728689e+00  2.09289349e+00  0.00000000e+00\n",
      "  0.00000000e+00 -1.00005487e+01  1.64009754e+00  0.00000000e+00\n",
      " -2.07631299e+01  1.17230400e+00  0.00000000e+00 -1.10787289e-01\n",
      "  2.51039204e+00]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Lasso model with a chosen alpha value\n",
    "lasso = Lasso(alpha=0.01, random_state=42)\n",
    "\n",
    "# Fit the Lasso model to the data\n",
    "lasso.fit(X, y)\n",
    "\n",
    "# Identify the features with non-zero coefficients\n",
    "selected_features = X.columns[(lasso.coef_ != 0)]\n",
    "print(\"Selected Features:\", selected_features)\n",
    "\n",
    "# If you want to see the coefficients\n",
    "print(\"Lasso Coefficients:\", lasso.coef_)\n",
    "\n",
    "X_selected = X[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two major things to note here:\n",
    "\n",
    "- **City**: It seems as though their Discount program was targeted by City, not by customer. We will have to keep this in mind when constructing models. Further, it does not seem as though, based on City alone, there was a strong effect of applying a discount; however, we cannot compare as we do not have independent data points.\n",
    "- **Gender**: Discounts were much more heavily applied to Female customers as compared to Male.\n",
    "\n",
    "Let's investigate how Discount Applied stacks up against both Gender and City together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    LinearRegression(): \"Linear Regression\",\n",
    "    RandomForestRegressor(random_state=42): \"Random Forest Regression\",\n",
    "    GradientBoostingRegressor(random_state=42): \"Gradient Boosting Regressor\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Male'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/scottpitcher/Desktop/python/Github/ecommerce-marketing-analytics-optimization/clv_optimization_model.ipynb Cell 23\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/scottpitcher/Desktop/python/Github/ecommerce-marketing-analytics-optimization/clv_optimization_model.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m model, name \u001b[39min\u001b[39;00m models\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/scottpitcher/Desktop/python/Github/ecommerce-marketing-analytics-optimization/clv_optimization_model.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/scottpitcher/Desktop/python/Github/ecommerce-marketing-analytics-optimization/clv_optimization_model.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/scottpitcher/Desktop/python/Github/ecommerce-marketing-analytics-optimization/clv_optimization_model.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# Predict on the test set\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/scottpitcher/Desktop/python/Github/ecommerce-marketing-analytics-optimization/clv_optimization_model.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/Desktop/python/Github/ecommerce-marketing-analytics-optimization/.venv/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/python/Github/ecommerce-marketing-analytics-optimization/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:609\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    605\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[1;32m    607\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 609\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    610\u001b[0m     X,\n\u001b[1;32m    611\u001b[0m     y,\n\u001b[1;32m    612\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m    613\u001b[0m     y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    614\u001b[0m     multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    615\u001b[0m     force_writeable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    616\u001b[0m )\n\u001b[1;32m    618\u001b[0m has_sw \u001b[39m=\u001b[39m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[39mif\u001b[39;00m has_sw:\n",
      "File \u001b[0;32m~/Desktop/python/Github/ecommerce-marketing-analytics-optimization/.venv/lib/python3.12/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    651\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/Desktop/python/Github/ecommerce-marketing-analytics-optimization/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1297\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     )\n\u001b[0;32m-> 1301\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1302\u001b[0m     X,\n\u001b[1;32m   1303\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1304\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1305\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1306\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1307\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1308\u001b[0m     force_writeable\u001b[39m=\u001b[39;49mforce_writeable,\n\u001b[1;32m   1309\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1310\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1311\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1312\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1313\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1314\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1315\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1316\u001b[0m )\n\u001b[1;32m   1318\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/Desktop/python/Github/ecommerce-marketing-analytics-optimization/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:929\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[39mif\u001b[39;00m pandas_requires_conversion:\n\u001b[1;32m    925\u001b[0m     \u001b[39m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[1;32m    926\u001b[0m     \u001b[39m# nans\u001b[39;00m\n\u001b[1;32m    927\u001b[0m     \u001b[39m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[1;32m    928\u001b[0m     new_dtype \u001b[39m=\u001b[39m dtype_orig \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m dtype\n\u001b[0;32m--> 929\u001b[0m     array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39;49mastype(new_dtype)\n\u001b[1;32m    930\u001b[0m     \u001b[39m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[1;32m    931\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/python/Github/ecommerce-marketing-analytics-optimization/.venv/lib/python3.12/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy, errors\u001b[39m=\u001b[39merrors) \u001b[39mfor\u001b[39;00m _, ser \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   6644\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[39m=\u001b[39mnew_data\u001b[39m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/python/Github/ecommerce-marketing-analytics-optimization/.venv/lib/python3.12/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[39melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    431\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    432\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    433\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    434\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    435\u001b[0m     using_cow\u001b[39m=\u001b[39;49musing_copy_on_write(),\n\u001b[1;32m    436\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/python/Github/ecommerce-marketing-analytics-optimization/.venv/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_blocks(result_blocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/Desktop/python/Github/ecommerce-marketing-analytics-optimization/.venv/lib/python3.12/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan not squeeze with more than one column.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[39m=\u001b[39m values[\u001b[39m0\u001b[39m, :]  \u001b[39m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m    760\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/python/Github/ecommerce-marketing-analytics-optimization/.venv/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    238\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[39m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/python/Github/ecommerce-marketing-analytics-optimization/.venv/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[39m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    184\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/python/Github/ecommerce-marketing-analytics-optimization/.venv/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mor\u001b[39;00m arr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m \u001b[39mor\u001b[39;00m dtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[39m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39;49mastype(dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Male'"
     ]
    }
   ],
   "source": [
    "for model, name in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Print model performance\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    print(f\"R-squared: {r2:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clv_model = RandomForestRegressor(random_state=42)\n",
    "clv_model.fit(X_train, y_train)\n",
    "print(\"CLV Prediction Model Trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Predicted_CLV_Baseline'] = clv_model.predict(X)\n",
    "data[[\"Total Spend\",\"Predicted_CLV_Baseline\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating interaction terms\n",
    "Using the ETL script, we will create interaction terms based on highly correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Discount_Items_Interaction'] = data['Discount Applied'] * data['Items Purchased']\n",
    "data['Discount_AverageRating_Interaction'] = data['Discount Applied'] * data['Average Rating']\n",
    "data['Discount_Satisfaction_Interaction'] = data['Discount Applied'] * data['Satisfaction Level']\n",
    "data['Discount_DaysSince_Interaction'] = data['Discount Applied'] * data['Days Since Last Purchase']\n",
    "data['Membership_Age_Discount_Interaction'] = data['Membership Type'] * data['Age'] * data['Discount Applied']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split Data into Treatment and Control Groups\n",
    "treatment = data[data['Discount Applied'] == 1]\n",
    "control = data[data['Discount Applied'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['Gender', 'City', 'Membership Type']\n",
    "\n",
    "for var in categorical_variables:\n",
    "    # Control Group\n",
    "    control_dist = control[var].value_counts(normalize=True)\n",
    "    \n",
    "    # Treatment Group\n",
    "    treatment_dist = treatment[var].value_counts(normalize=True)\n",
    "    \n",
    "    # Create a 1x2 grid of pie charts\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Control Group Pie Chart\n",
    "    axes[0].pie(control_dist, labels=control_dist.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette('pastel'))\n",
    "    axes[0].set_title(f'{var} Distribution in No Discount Group')\n",
    "    \n",
    "    # Treatment Group Pie Chart\n",
    "    axes[1].pie(treatment_dist, labels=treatment_dist.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette('pastel'))\n",
    "    axes[1].set_title(f'{var} Distribution in Discount Group')\n",
    "    \n",
    "    # Display the plots\n",
    "    plt.suptitle(f'Comparison of {var} Distribution between Control and Treatment Groups')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the mean CLV of the test and control groups for each feature\n",
    "features_to_test = ['Gender', 'City', 'Membership Type', \n",
    "                    'Discount_Satisfaction_Interaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_mean = control.groupby('City')['Total Spend'].mean()\n",
    "print(control_mean)\n",
    "test_mean = treatment.groupby('City')['Total Spend'].mean()\n",
    "print(test_mean)\n",
    "uplift = test_mean - control_mean\n",
    "print(f\"Uplift in CLV for 'City': \\n{uplift}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistical Analysis of Features' Response to Discount:\")\n",
    "for feature in features_to_test:\n",
    "    control_mean = control.groupby(feature)['Total Spend'].mean()\n",
    "    test_mean = treatment.groupby(feature)['Total Spend'].mean()\n",
    "    uplift = test_mean - control_mean\n",
    "    print(f\"Uplift in CLV for {feature}: \\n{uplift}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target for treatment group\n",
    "X_treatment = treatment.drop(columns = \"Total Spend\")\n",
    "y_treatment = treatment['Total Spend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target\n",
    "X_control = control.drop(columns = \"Total Spend\")\n",
    "y_control = control['Total Spend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "treatment_model = GradientBoostingRegressor(random_state=42)\n",
    "control_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Train models\n",
    "treatment_model.fit(X_treatment, y_treatment)\n",
    "control_model.fit(X_control, y_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict CLV for both groups\n",
    "treatment_predictions = treatment_model.predict(X_treatment)\n",
    "control_predictions = control_model.predict(X_control)\n",
    "\n",
    "# Calculate the expected uplift for each customer\n",
    "data['Predicted_CLV_Treatment'] = treatment_model.predict(data[X_treatment.columns])\n",
    "data['Predicted_CLV_Control'] = control_model.predict(data[X_control.columns])\n",
    "data['Uplift'] = data['Predicted_CLV_Treatment'] - data['Predicted_CLV_Control']\n",
    "\n",
    "data[['Predicted_CLV_Treatment','Predicted_CLV_Control','Uplift']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Predicted_CLV_Treatment','Predicted_CLV_Control','Uplift']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uplift_threshold = data['Uplift'].quantile(0.50)  # Adjust this threshold as needed\n",
    "data['Target_for_Discount'] = data['Uplift'] > uplift_threshold\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uplift distribution\n",
    "sns.histplot(data['Uplift'], kde=True)\n",
    "plt.title('Uplift Distribution')\n",
    "plt.xlabel('Uplift (Predicted CLV Treatment - Predicted CLV Control)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of customers targeted for discount\n",
    "target_ratio = data['Target_for_Discount'].mean() * 100\n",
    "print(f\"\\nPercentage of customers identified to receive a discount: {target_ratio:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average uplift for customers who are targeted\n",
    "average_uplift = data[data['Target_for_Discount'] == True]['Uplift'].mean()\n",
    "print(f\"\\nAverage uplift in CLV for targeted customers: ${average_uplift:.2f}\")\n",
    "\n",
    "# Potential increase in revenue if targeted customers receive discounts\n",
    "potential_increase = average_uplift * data['Target_for_Discount'].sum()\n",
    "print(f\"Potential increase in revenue from targeted discounts: ${potential_increase:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(treatment_model, 'feature_importances_'):\n",
    "    feature_importance = pd.Series(treatment_model.feature_importances_, index=X_control.columns).sort_values(ascending=False)\n",
    "    sns.barplot(x=feature_importance.values, y=feature_importance.index)\n",
    "    plt.title('Feature Importance for Treatment Group')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.ylabel('Features')\n",
    "    plt.show()\n",
    "\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create groups\n",
    "control_group = data[data['Discount Applied'] == 0]['Total Spend']\n",
    "test_group = data[data['Discount Applied'] == 1]['Total Spend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p_value = stats.ttest_ind(control_group, test_group, equal_var=False)\n",
    "print(f'\\nA/B Testing Results:')\n",
    "print(f'Test Group Mean CLV: {test_group.mean():.2f}')\n",
    "print(f'Control Group Mean CLV: {control_group.mean():.2f}')\n",
    "print(f'T-statistic: {t_stat:.2f}, P-value: {p_value:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
